{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9044d079-c6ba-4b92-a85e-b0ce6ec3ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(['loan_status', 'id'], axis=1)\n",
    "y = df['loan_status']\n",
    "\n",
    "# Split train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2619a974-bd1c-49b8-a565-bc5713dd4896",
   "metadata": {},
   "source": [
    "# TensorFlow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c90131-7fca-4c4d-b759-0eb20db8013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Automatically identify categorical and numerical columns based on dtype\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07b77b6a-a321-497d-a5cb-feccfb95087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.9005 - loss: 0.2778 - val_accuracy: 0.9408 - val_loss: 0.1962\n",
      "Epoch 2/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.9304 - loss: 0.2095 - val_accuracy: 0.9411 - val_loss: 0.1889\n",
      "Epoch 3/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.9380 - loss: 0.1969 - val_accuracy: 0.9433 - val_loss: 0.1849\n",
      "Epoch 4/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - accuracy: 0.9411 - loss: 0.1908 - val_accuracy: 0.9463 - val_loss: 0.1826\n",
      "Epoch 5/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.9427 - loss: 0.1871 - val_accuracy: 0.9465 - val_loss: 0.1822\n",
      "Epoch 6/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.9419 - loss: 0.1864 - val_accuracy: 0.9422 - val_loss: 0.1851\n",
      "Epoch 7/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.9420 - loss: 0.1875 - val_accuracy: 0.9439 - val_loss: 0.1848\n",
      "Epoch 8/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.9459 - loss: 0.1759 - val_accuracy: 0.9466 - val_loss: 0.1809\n",
      "Epoch 9/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.9429 - loss: 0.1843 - val_accuracy: 0.9474 - val_loss: 0.1786\n",
      "Epoch 10/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 0.9458 - loss: 0.1763 - val_accuracy: 0.9483 - val_loss: 0.1762\n",
      "Epoch 11/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.9441 - loss: 0.1848 - val_accuracy: 0.9492 - val_loss: 0.1771\n",
      "Epoch 12/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.9470 - loss: 0.1749 - val_accuracy: 0.9483 - val_loss: 0.1774\n",
      "Epoch 13/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.9460 - loss: 0.1747 - val_accuracy: 0.9493 - val_loss: 0.1755\n",
      "Epoch 14/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.9476 - loss: 0.1742 - val_accuracy: 0.9475 - val_loss: 0.1793\n",
      "Epoch 15/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - accuracy: 0.9460 - loss: 0.1781 - val_accuracy: 0.9479 - val_loss: 0.1775\n",
      "Epoch 16/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.9464 - loss: 0.1753 - val_accuracy: 0.9492 - val_loss: 0.1755\n",
      "Epoch 17/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.9487 - loss: 0.1742 - val_accuracy: 0.9474 - val_loss: 0.1800\n",
      "Epoch 18/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.9457 - loss: 0.1770 - val_accuracy: 0.9481 - val_loss: 0.1767\n",
      "Epoch 19/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - accuracy: 0.9467 - loss: 0.1750 - val_accuracy: 0.9475 - val_loss: 0.1765\n",
      "Epoch 20/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - accuracy: 0.9456 - loss: 0.1762 - val_accuracy: 0.9480 - val_loss: 0.1781\n",
      "Epoch 21/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - accuracy: 0.9505 - loss: 0.1644 - val_accuracy: 0.9484 - val_loss: 0.1776\n",
      "Epoch 22/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.9470 - loss: 0.1731 - val_accuracy: 0.9491 - val_loss: 0.1747\n",
      "Epoch 23/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 0.9482 - loss: 0.1728 - val_accuracy: 0.9490 - val_loss: 0.1759\n",
      "Epoch 24/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.9495 - loss: 0.1686 - val_accuracy: 0.9498 - val_loss: 0.1761\n",
      "Epoch 25/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.9478 - loss: 0.1724 - val_accuracy: 0.9484 - val_loss: 0.1785\n",
      "Epoch 26/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.9486 - loss: 0.1683 - val_accuracy: 0.9493 - val_loss: 0.1754\n",
      "Epoch 27/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.9481 - loss: 0.1728 - val_accuracy: 0.9499 - val_loss: 0.1749\n",
      "Epoch 28/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.9505 - loss: 0.1668 - val_accuracy: 0.9474 - val_loss: 0.1793\n",
      "Epoch 29/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.9501 - loss: 0.1654 - val_accuracy: 0.9494 - val_loss: 0.1763\n",
      "Epoch 30/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.9486 - loss: 0.1705 - val_accuracy: 0.9497 - val_loss: 0.1782\n",
      "Epoch 31/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.9499 - loss: 0.1672 - val_accuracy: 0.9504 - val_loss: 0.1751\n",
      "Epoch 32/100\n",
      "\u001b[1m1173/1173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.9488 - loss: 0.1663 - val_accuracy: 0.9480 - val_loss: 0.1819\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step\n",
      "TF Accuracy: 0.9481626737147242\n",
      "TF ROC AUC: 0.8468679281135599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     10054\n",
      "           1       0.91      0.71      0.80      1675\n",
      "\n",
      "    accuracy                           0.95     11729\n",
      "   macro avg       0.93      0.85      0.88     11729\n",
      "weighted avg       0.95      0.95      0.95     11729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from tqdm.notebook import tqdm # for Jupyter notebooks\n",
    "# For terminal use: from tqdm import tqdm\n",
    "\n",
    "# Create TensorFlow model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_preprocessed.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_preprocessed, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = model.predict(X_test_preprocessed)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Evaluate\n",
    "print(f\"TF Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"TF ROC AUC: {roc_auc_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9df2f55-779c-4877-8cac-10fbca5855d5",
   "metadata": {},
   "source": [
    "## PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "921c0db4-1f50-4449-9caa-5eb84bff18a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple MPS is not available, using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Check if Apple MPS if available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using Apple MPS device\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Apple MPS is not available, using {device} device\")\n",
    "\n",
    "# Convert to PyTorch tensors and move to device (if available)\n",
    "X_train_tensor = torch.FloatTensor(\n",
    "    X_train_preprocessed.toarray() if hasattr(X_train_preprocessed, 'toarray') else X_train_preprocessed\n",
    ").to(device)\n",
    "X_test_tensor = torch.FloatTensor(\n",
    "    X_test_preprocessed.toarray() if hasattr(X_test_preprocessed, 'toarray') else X_test_preprocessed\n",
    ").to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1).to(device)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Define the model\n",
    "class LoanModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LoanModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "model = LoanModel(input_dim)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6e81112-ae26-4d39-8c27-ba175c91e678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f40de5184243ad96970d9630abc9c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c900e5c4aeb4afd9d28a570d392ebec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7836f92b3343e0a1734f72caee003f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e67b029fed41b7b23ec90a29adae23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f772e362c7e45ecb775495f2c177001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ff783c49774612a76d4063f9d4b9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8dcea1154e4f9ea384d5bc08f5e924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8f913537144daa86d9e370760527e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587681eba006493fa844646ba5e2df87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b8896d63cb4b9793aa0b59c7ef1a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424ea875719c4f23b16e85908a5cde03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8786687769924f0ea1cb5884b7a50710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bbb79780dd4068ab2c7802262edad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4d082975184161ac976beaeae59e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7bfe7f1ad5448792f76bf045d209ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5f3545e34e492ca75765b9cf3a7c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6643a9a2e42140fbbfa50efdd1c32fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ca9317e52e43ad9da678443ff4fa80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e3d5198e12453b8567331e2dbff1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22495538af2a4bb08ee43fc350868676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/20 [Train]:   0%|          | 0/1467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=50):\n",
    "    # Track metrics across epochs\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': []\n",
    "    }\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Use tqdm.notebook for Jupyter integration\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs).squeeze()\n",
    "            labels = labels.squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Statistics\n",
    "            # Explicitly tells PyTorch to detach the tensor from the computation graph before converting it to a scalar\n",
    "            # Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
    "            running_loss += loss.detach().item() * inputs.size(0)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = 100 * correct / total\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "    return history\n",
    "    \n",
    "# Train the model\n",
    "history = train_model(model, train_loader, criterion, optimizer, num_epochs=20)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'loan_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ba4290c-33c0-4467-9b20-8d85b7e0ff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 95.0294%\n"
     ]
    }
   ],
   "source": [
    "# Function to make predictions\n",
    "def predict(model, X_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_tensor)\n",
    "\n",
    "    return (outputs > 0.5).float().numpy()\n",
    "\n",
    "# Make predictions\n",
    "y_pred = predict(model, X_test_tensor)\n",
    "print(f\"Validation accuracy: {100 * np.mean(y_pred.flatten() == y_test.values):.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8448ac2-9b2a-4fe6-977a-f7eb17af2eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
