{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b4054b-2312-4369-ad49-52caa10fafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864f052f-76ec-46dc-b06f-a93c6a39db97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length']\n",
      "Categorical columns: ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(['loan_status', 'id'], axis=1)\n",
    "y = df['loan_status']\n",
    "\n",
    "# Automatically identify categorical and numerical columns based on dtype\n",
    "# Numerical columns: int64, float64\n",
    "# Categorical columns: object, category, bool\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce9996-aed8-458a-95fc-013d2f7497db",
   "metadata": {},
   "source": [
    "# 1. Scikit-learn implementation\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d641a0-b795-4a10-a8d4-3c476d0ad2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Accuracy: 0.9141\n",
      "ROC AUC: 0.7615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     10054\n",
      "           1       0.79      0.55      0.65      1675\n",
      "\n",
      "    accuracy                           0.91     11729\n",
      "   macro avg       0.86      0.76      0.80     11729\n",
      "weighted avg       0.91      0.91      0.91     11729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# Create pipeline with preprocessing and logistic regression\n",
    "log_reg_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=21, max_iter=1000))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_reg_pipeline.predict(X_test)\n",
    "y_pred_proba = log_reg_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate \n",
    "print(\"Logistic Regression Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e9d25-3346-4ccf-8369-c72afcd8667a",
   "metadata": {},
   "source": [
    "## Scikit-learn: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "449a15da-5e1e-435d-9b08-082e638fb4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "Accuracy: 0.9513\n",
      "ROC AUC: 0.8527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     10054\n",
      "           1       0.93      0.71      0.81      1675\n",
      "\n",
      "    accuracy                           0.95     11729\n",
      "   macro avg       0.94      0.85      0.89     11729\n",
      "weighted avg       0.95      0.95      0.95     11729\n",
      "\n",
      "Feature ranking:\n",
      "1. loan_percent_income (0.2358)\n",
      "2. loan_int_rate (0.1186)\n",
      "3. person_income (0.1065)\n",
      "4. loan_grade_D (0.0916)\n",
      "5. loan_amnt (0.0727)\n",
      "6. person_emp_length (0.0629)\n",
      "7. person_home_ownership_RENT (0.0531)\n",
      "8. person_age (0.0455)\n",
      "9. cb_person_cred_hist_length (0.0362)\n",
      "10. person_home_ownership_MORTGAGE (0.0277)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create pipeline with preprocessing and Random Forest\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=21))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "y_pred_proba = rf_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate \n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_names = (\n",
    "    numerical_cols + \n",
    "    rf_pipeline.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_cols).tolist()\n",
    ")\n",
    "importances = rf_pipeline.named_steps['classifier'].feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(min(10, len(feature_names))):\n",
    "    print(f\"{f+1}. {feature_names[indices[f]]} ({importances[indices[f]]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb216452-33f7-4e71-8993-aabddf76e4ae",
   "metadata": {},
   "source": [
    "## Scikit-learn: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd57521-ab1f-4a10-ae14-30e07ec9e1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Results:\n",
      "Accuracy: 0.9517\n",
      "ROC AUC: 0.8566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     10054\n",
      "           1       0.92      0.72      0.81      1675\n",
      "\n",
      "    accuracy                           0.95     11729\n",
      "   macro avg       0.94      0.86      0.89     11729\n",
      "weighted avg       0.95      0.95      0.95     11729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create pipeline with preprocessing and Gradient Boosting\n",
    "gb_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=100, random_state=21))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "gb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gb_pipeline.predict(X_test)\n",
    "y_pred_proba = gb_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate \n",
    "print(\"Gradient Boosting Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed527f1-df47-4f9b-b912-8850827d4bd4",
   "metadata": {},
   "source": [
    "## Scikit-learn: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f941a543-ba85-4699-a8d0-9f61aa0af4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "Accuracy: 0.9439\n",
      "ROC AUC: 0.8312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     10054\n",
      "           1       0.91      0.67      0.77      1675\n",
      "\n",
      "    accuracy                           0.94     11729\n",
      "   macro avg       0.93      0.83      0.87     11729\n",
      "weighted avg       0.94      0.94      0.94     11729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create pipeline with preprocessing and SVM\n",
    "svm_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC(probability=True, random_state=21))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_pipeline.predict(X_test)\n",
    "y_pred_proba = svm_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate \n",
    "print(\"SVM Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a87b91-cabf-4d0a-8f9d-25f67e8ee6f7",
   "metadata": {},
   "source": [
    "## Scikit-learn: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80dbdcbc-0473-4b08-9ff6-66507f1a06ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "Accuracy: 0.9318\n",
      "ROC AUC: 0.8129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     10054\n",
      "           1       0.84      0.65      0.73      1675\n",
      "\n",
      "    accuracy                           0.93     11729\n",
      "   macro avg       0.89      0.81      0.85     11729\n",
      "weighted avg       0.93      0.93      0.93     11729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create pipeline with preprocessing and KNN\n",
    "knn_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn_pipeline.predict(X_test)\n",
    "y_pred_proba = knn_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate \n",
    "print(\"KNN Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9956496-f674-4352-886f-7be4002ee5fc",
   "metadata": {},
   "source": [
    "## Scikit-learn: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db193a11-73b5-4ea2-bff1-38278cd324bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Results:\n",
      "Accuracy: 0.9143\n",
      "ROC AUC: 0.8351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     10054\n",
      "           1       0.69      0.72      0.71      1675\n",
      "\n",
      "    accuracy                           0.91     11729\n",
      "   macro avg       0.82      0.84      0.83     11729\n",
      "weighted avg       0.92      0.91      0.92     11729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create pipeline with preprocessing and KNN\n",
    "dt_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=21))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = dt_pipeline.predict(X_test)\n",
    "y_pred_proba = dt_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate \n",
    "print(\"KNN Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b365c31-e67c-4e10-969c-895749572e4a",
   "metadata": {},
   "source": [
    "## Model Comparison and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2f14604-664b-491f-8635-586e5925d95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results:\n",
      "Logistic Regression: Mean ROC AUC = 0.9020, Std = 0.0021\n",
      "Random Forest: Mean ROC AUC = 0.9343, Std = 0.0023\n",
      "Gradient Boosting: Mean ROC AUC = 0.9398, Std = 0.0027\n",
      "SVM: Mean ROC AUC = 0.8916, Std = 0.0064\n",
      "KNN: Mean ROC AUC = 0.8773, Std = 0.0048\n",
      "Decision Tree: Mean ROC AUC = 0.8325, Std = 0.0083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# List of models to compare\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=21, max_iter=1000)),\n",
    "    ('Random Forest', RandomForestClassifier(random_state=21)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=21)),\n",
    "    ('SVM', SVC(probability=True, random_state=21)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=21))\n",
    "]\n",
    "\n",
    "# Compare models using cross-validation\n",
    "print(\"Cross-Validation Results:\")\n",
    "for name, model in models:\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring='roc_auc')\n",
    "    print(f\"{name}: Mean ROC AUC = {scores.mean():.4f}, Std = {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a8dbd9-cc40-440d-9308-582b1bdec729",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7284eeba-1548-447e-889e-7583a886e73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best parameters: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 200}\n",
      "Best ROC AUC score: 0.9376\n",
      "Best RF Model Results:\n",
      "Accuracy: 0.9513\n",
      "ROC AUC: 0.8512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     10054\n",
      "           1       0.93      0.71      0.81      1675\n",
      "\n",
      "    accuracy                           0.95     11729\n",
      "   macro avg       0.94      0.85      0.89     11729\n",
      "weighted avg       0.95      0.95      0.95     11729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Tuning Random Forest\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=21)\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', rf_model)\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    rf_pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best ROC AUC score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Use the best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "y_pred_proba = best_rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate \n",
    "print(\"Best RF Model Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fbe529-9bf0-4042-a047-1c1e04abfcef",
   "metadata": {},
   "source": [
    "## Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "353603ce-d16b-454f-969f-b196318e226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Ensemble Results:\n",
      "Accuracy: 0.9518\n",
      "ROC AUC: 0.8565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     10054\n",
      "           1       0.92      0.72      0.81      1675\n",
      "\n",
      "    accuracy                           0.95     11729\n",
      "   macro avg       0.94      0.86      0.89     11729\n",
      "weighted avg       0.95      0.95      0.95     11729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=21)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=21)),\n",
    "    ('lr', LogisticRegression(random_state=21))\n",
    "]\n",
    "\n",
    "# Define meta-learner\n",
    "meta_learner = LogisticRegression(random_state=21)\n",
    "\n",
    "# Create stacking ensemble\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_learner,\n",
    "    cv=5,\n",
    "    stack_method='predict_proba'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and stacking ensemble\n",
    "stack_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', stacking_clf)\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "stack_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = stack_pipeline.predict(X_test)\n",
    "y_pred_proba = stack_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate \n",
    "print(\"Stacking Ensemble Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e29e56-e135-423b-a73e-5fe960941c3d",
   "metadata": {},
   "source": [
    "## Scikit-learn: Multi Layer Perceptron (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "208bf622-25f6-415e-80ba-237867601071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn MLP Accuracy: 0.9279563475147071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96     10054\n",
      "           1       0.77      0.71      0.74      1675\n",
      "\n",
      "    accuracy                           0.93     11729\n",
      "   macro avg       0.86      0.84      0.85     11729\n",
      "weighted avg       0.93      0.93      0.93     11729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create pipeline with preprocessing and MLP classifier\n",
    "mlp_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', MLPClassifier(hidden_layer_sizes=(100, 50),\n",
    "                                max_iter=1000,\n",
    "                                activation='relu',\n",
    "                                solver='adam',\n",
    "                                random_state=21))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "mlp_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mlp_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(f\"Scikit-learn MLP Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1979e2-01db-43af-8543-26559c931c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
